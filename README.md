# å¤è¯—è¯åˆ›ä½œåŠ©æ‰‹ :blush:	

## ä»‹ç» ğŸ˜Š

â€‹	æ¬¢è¿ä½¿ç”¨æˆ‘ä»¬çš„å¤è¯—è¯åˆ›ä½œåŠ©æ‰‹å¤§è¯­è¨€æ¨¡å‹ï¼è¿™ä¸ªæ¨¡å‹æ˜¯åŸºäº`CCPM (Chinese Classical Poetry Matching)`æä¾›çš„ä¸°å¯Œä¸­å›½å¤ä»£è¯—è¯æ•°æ®é›†å¼€å‘è€Œæˆã€‚æˆ‘ä»¬çš„æ•°æ®é›†æ˜¯ä¸€ä¸ªå¤§å‹çš„ä¸­å›½å¤å…¸è¯—æ­ŒåŒ¹é…æ•°æ®é›†ï¼Œå¯ç”¨äºè¯—æ­ŒåŒ¹é…ã€ç†è§£å’Œç¿»è¯‘ã€‚

â€‹	æˆ‘ä»¬çš„æ¨¡å‹æ˜¯æ‚¨åˆ›ä½œå¤å…¸è¯—æ­Œçš„å°åŠ©æ‰‹ï¼Œå…·å¤‡ä¸°å¯Œçš„å¤å…¸è¯—æ­ŒçŸ¥è¯†å’Œæ„è±¡è¯†åˆ«ã€è¯—æ­Œç¿»è¯‘èƒ½åŠ›ã€‚æ— è®ºæ‚¨æ˜¯æƒ³äº†è§£ä¸€é¦–è¯—æ­Œçš„å†™ä½œèƒŒæ™¯ã€æƒ…æ„Ÿè¡¨è¾¾ï¼Œç”šè‡³éœ€è¦åˆ›ä½œä¸€é¦–å±äºæ‚¨çš„è¯—æ­Œï¼Œæˆ‘ä»¬éƒ½èƒ½ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚

å¦‚ä½•å­¦ä¹ å¤§æ¨¡å‹éƒ¨ç½²å’Œå¾®è°ƒè¯·å‚è€ƒï¼š[å¼€æºå¤§æ¨¡å‹é£Ÿç”¨æŒ‡å—](https://github.com/datawhalechina/self-llm.git) ä»¥åŠ [ä¹¦ç”ŸÂ·æµ¦è¯­å¤§æ¨¡å‹å®æˆ˜è¥è¯¾ç¨‹](https://github.com/InternLM/tutorial.git)

## OpenXlab æ¨¡å‹

å¤è¯—è¯åˆ›ä½œåŠ©æ‰‹ä½¿ç”¨çš„æ˜¯InternLM çš„ 7B æ¨¡å‹ï¼Œæ¨¡å‹å‚æ•°é‡ä¸º 7Bï¼Œæ¨¡å‹å·²ä¸Šä¼ ï¼Œå¯ä»¥ç›´æ¥ä¸‹è½½æ¨ç†ã€‚

| åŸºåº§æ¨¡å‹         | å¾®è°ƒæ•°æ®é‡          | è®­ç»ƒæ¬¡æ•° | 
| ---------------- | ------------------- | -------- | 
| InternLM-chat-7b | 27218 conversations | 10 epochs | 

## æ•°æ®é›†

â€‹	å¤è¯—è¯åˆ›ä½œåŠ©æ‰‹æ•°æ®é›†é‡‡ç”¨ä¸­çš„`CCPM (Chinese Classical Poetry Matching)`æ˜¯ä¸€ä¸ªå¤§å‹çš„ä¸­å›½å¤å…¸è¯—æ­ŒåŒ¹é…æ•°æ®é›†ï¼Œå¯ç”¨äºè¯—æ­ŒåŒ¹é…ã€ç†è§£å’Œç¿»è¯‘ï¼Œå…±è®¡ 27218ä¸ªå®ä¾‹ï¼Œæ•°æ®é›†æ ·ä¾‹ï¼š

```
"input": "ä¾å¥‰å¤«ä¸»ï¼Œä¸èƒ½å°½è‡ªå·±çš„å¤©å¹´ã€‚"
"output": "äº‹ä¸»ä¸å°½å¹´"
"input": "ä¸ºç‹äº‹å¥”æ³¢è·¯ç¨‹å°šæ²¡æœ‰èµ°å°½ã€‚"
"output": "ç‹ç¨‹åº”æœªå°½"
```

### æ•°æ®å¤„ç†ä¸æ•´ç†

1. æ•°æ®é›†æ˜¯ä»¥jsonæ ¼å¼å­˜å‚¨çš„ï¼Œç„¶è€Œæ ¼å¼æœ‰ä¸€å®šé—®é¢˜ã€‚
2. éœ€è¦åˆ é™¤éƒ¨åˆ†ä¸ç¬¦åˆå®æ„çš„æ•°æ®ã€‚
3. è¿›è¡Œæ ¼å¼è½¬æ¢ã€‚

ä½¿ç”¨å¦‚ä¸‹è„šæœ¬æ–‡ä»¶

```

# æŒ‡å®šè¾“å…¥çš„JSONæ–‡ä»¶
import json

def convert_to_json(jsonl_file):
    conversations = []
    with open(jsonl_file, 'r', encoding='utf-8') as f:
        for line in f:
            data = json.loads(line)
            input_text = data["fanyi"].strip()
            input_text = input_text.replace('æ³¨é‡Š','')
            if input_text:  # å¦‚æœinputå­—æ®µä¸ä¸ºç©º
                conversation = {
                    "input": input_text,
                    "output": data["content"]
                }
                conversations.append({"conversation": [conversation]})
    return conversations

def write_to_json(output_file, conversations):
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(conversations, f, ensure_ascii=False, indent=4)

def main(jsonl_file, output_file):
    conversations = convert_to_json(jsonl_file)
    write_to_json(output_file, conversations)

if __name__ == "__main__":
    jsonl_file = "dugushici-com-70k.json"
    output_file = "output4.json"
    main(jsonl_file, output_file)

```

## å¾®è°ƒ

â€ƒâ€ƒä½¿ç”¨ `XTuner `è®­ç»ƒï¼Œ `XTuner `æœ‰å„ä¸ªæ¨¡å‹çš„ä¸€é”®è®­ç»ƒè„šæœ¬ï¼Œå¾ˆæ–¹ä¾¿ã€‚ä¸”å¯¹` InternLM2 `çš„æ”¯æŒåº¦æœ€é«˜ã€‚

### XTuner

â€ƒâ€ƒä½¿ç”¨ `XTuner` è¿›è¡Œå¾®è°ƒï¼Œå…·ä½“è„šæœ¬å¯å‚è€ƒ`configs`æ–‡ä»¶å¤¹ä¸‹çš„è„šæœ¬ï¼Œè„šæœ¬å†…æœ‰è¾ƒä¸ºè¯¦ç»†çš„æ³¨é‡Šã€‚

| åŸºåº§æ¨¡å‹         | é…ç½®æ–‡ä»¶                               |
| ---------------- | -------------------------------------- |
| internlm-chat-7b | internlm_chat_7b_qlora_oasst1_e3.py |

å¾®è°ƒæ–¹æ³•å¦‚ä¸‹:

1. æ ¹æ®åŸºåº§æ¨¡å‹å¤åˆ¶ä¸Šé¢çš„é…ç½®æ–‡ä»¶ï¼Œå°†æ¨¡å‹åœ°å€`pretrained_model_name_or_path`å’Œæ•°æ®é›†åœ°å€`data_path`ä¿®æ”¹æˆè‡ªå·±çš„

```
conda activate xtuner0.1.9
cd ~/gushi
xtuner train ./internlm_chat_7b_qlora_oasst1_e3_copy.py --deepspeed deepspeed_zero2
```

æ­¤å¤–ï¼Œä¸ºäº†å¢å¼ºæ•ˆæœï¼Œå¢åŠ å¯¹æ¨¡å‹çš„æç¤ºè¯ã€‚

è®­ç»ƒå‰ï¼š
![](./imgs/pre_p.png)

è®­ç»ƒæ•ˆæœï¼š
![](./imgs/pre.png)

2. å°†å¾—åˆ°çš„ PTH æ¨¡å‹è½¬æ¢ä¸º HuggingFace æ¨¡å‹ï¼Œå¹¶ä¸åŸºåº§æ¨¡å‹åˆå¹¶ã€‚

```
internlm_chat_7b_qlora_oasst1_e3
xtuner convert pth_to_hf ./internlm_chat_7b_qlora_oasst1_e3.py ./work_dirs/internlm_chat_7b_qlora_oasst1_e3/epoch_10.pth ./hf
xtuner convert merge ./internlm-chat-7b ./hf ./merged --max-shard-size 2GB
```

## æœ¬åœ°ç½‘é¡µéƒ¨ç½²

```
# PowerShellè¿è¡Œ
ssh -CNg -L 6006:127.0.0.1:6006 root@ssh.intern-ai.org.cn -p 37845

```

æ•ˆæœæ¼”ç¤º
![](./imgs/las.png)
